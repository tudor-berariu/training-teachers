debug: no
no_cuda: no
epochs_no: 200
log_interval: 12800
student_eval_interval: 60000
professor_eval_interval: 300000

batch_size: 128
test_batch_size: 10000
in_size: [1, 32, 32]

random_params: yes
nstudents: 4
random_students: yes
reset_student: 10000

tasks:
  - FashionMNIST

student:
  name: ConvNet
  channels: [32, 32]
  units: [100]
  use_bias: False
  use_dropout: True

student_optimizer:
  name: Adam
  lr: 0.001
  nesterov: delete

c_l2: .0005

professor_type: generative

loss_learning:
  debug: no

  encoder:
    name: Encoder
  generator:
    name: Generator
    ngf: 16
  discriminator:
    name: OutputDiscriminator

  nz: 32

  c_nll: 0
  c_kl: 1
  c_grad_mse: 0
  c_grad_cos: 0
  c_next_nll: 0
  c_hess: 0
  c_d: 0
  c_next_kl: 0
  c_recon: 0
  c_latent_kl: .001

  grad_type: class
  next_lr: .001

  optimizer:
    name: Adam
    lr: .001
    nesterov: delete
    momentum: delete

  eval_samples: 128

evaluation:
  nstudents: 3
  teaching_steps: 1500
  teaching_eval_freq: 25
