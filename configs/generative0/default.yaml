debug: no
no_cuda: no
epochs_no: 50
log_interval: 10000
student_eval_interval: 60000
professor_eval_interval: 300000

batch_size: 256
test_batch_size: 10000
in_size: [1, 32, 32]

nstudents: 5
student:
  name: ConvNet
  channels: [32, 32]
  units: [200]
  use_bias: False
  use_dropout: False

student_optimizer:
  name: Adam
  lr: 0.001
  nesterov: delete

c_l2: .0005

professor_type: generative
reset_student: 60000


loss_learning:
  debug: no
  data_generator:
    name: SyntheticDataGenerator
    nz: 64
    ngf: 8

  c_nll: 1
  c_kl: 1
  c_grad: 1
  c_cos: 1
  batch_grad: False
  c_optim: 1
  c_hess: 0.0001
  c_d: 1

  full_grad: no

  optimizer:
    name: Adam
    lr: .001
    nesterov: delete
    momentum: delete

  eval_samples: 128

evaluation:
  random_params: yes
  nstudents: 5
  teaching_steps: 2500
  teaching_eval_freq: 125
