debug: no
no_cuda: no
epochs_no: 100
log_interval: 30000
eval_interval: 600000

batch_size: 256
test_batch_size: 10000
in_size: [1, 32, 32]

nstudents: 5
student:
  name: ConvNet
  channels: [16, 32]
  units: [200]
  use_bias: False
  use_dropout: True

student_optimizer:
  name: Adam
  lr: 0.001
  nesterov: delete

c_l2: .0005

professor_type: generative
reset_student: 60000


loss_learning:
  debug: no
  data_generator:
    name: SyntheticDataGenerator
    nz: 100
    ngf: 8

  c_nll: 0
  c_kl: 0
  c_grad: 0
  c_cos: 0
  batch_grad: False
  c_optim: 0
  c_hess: 0
  c_d: 0

  optimizer:
    name: Adam
    lr: .001
    nesterov: delete
    momentum: delete

  eval_samples: 128

evaluation:
  random_params: yes
  nstudents: 5
  teaching_steps: 2500
  teaching_eval_freq: 125
