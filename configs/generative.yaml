debug: no
no_cuda: no
epochs_no: 200
log_interval: 12800
student_eval_interval: 60000
professor_eval_interval: 240000

batch_size: 128
test_batch_size: 10000
in_size: [1, 32, 32]

random_params: yes
nstudents: 9
random_students: no

tasks:
  - FashionMNIST

student:
  name: ConvNet
  channels: [32, 32]
  units: [100]
  use_bias: False
  use_dropout: True

student_optimizer:
  name: Adam
  lr: 0.001
  nesterov: delete

c_l2: .0001

professor_type: generative

reset_student: 120000
professor_starts_student: no

loss_learning:
  debug: no

  encoder:
    name: LinearEncoder
    nef: 8
  generator:
    name: SkipGenerator
    ngf: 16
  discriminator:
    name: OutputDiscriminator

  nz: 32

  c_nll: 0
  c_kl: 1
  c_contrast_kl: 0.5
  c_grad_mse: 0
  c_grad_cos: 0
  c_next_nll: 0
  c_contrast_next_nll: 0
  c_next_nll2: 0
  c_hess: 0
  c_d: 0.5
  c_next_kl: 0
  c_recon: 0
  c_latent_kl: 0.1

  target_dropout: 0

  grad_type: example
  grad_samples: 20
  next_lr: .001

  rand_permute_outputs: yes

  optimizer:
    name: Adam
    lr: .001
    nesterov: delete
    momentum: delete

  eval_samples: 128
  student_train_on_fake: yes

evaluation:
  nstudents: 5
  teaching_steps: 2000
  teaching_eval_freq: 25
